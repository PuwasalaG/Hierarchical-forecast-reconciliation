%&latex
\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage{url} % not crucial - just used below for the URL 

\usepackage{amssymb, qtree, bm, multirow, textcmds, siunitx,paralist}
\usepackage{mathrsfs, float, booktabs,todonotes,amsthm}
\usepackage[bb=boondox]{mathalfa}
\usepackage{tikz}
\usetikzlibrary{arrows,positioning,shapes,fit,calc}
\usepackage{amsfonts}

\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{1}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{-.3in}%
\addtolength{\topmargin}{-.8in}%

\DeclareMathOperator*{\argmin}{arg\,min}
\newcolumntype{L}{>{$}l<{$}} % math-mode version of "l" column type
\def\mathbi#1{\textit{ #1}}
\def\mathB#1{\textbf{ #1}}
\def\E{\text{E}}
\def\var{\text{Var}}

\def\PQ{\begin{pmatrix}\bm{G}\\[-0.2cm]\bm{H}\end{pmatrix}}
\def\bt{\begin{pmatrix}\tilde{\bm{b}}\\[-0.2cm]\tilde{\bm{a}}\end{pmatrix}}

%\theoremstyle{theo}
\newtheorem{theo}{Theorem}[section]

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]



\begin{document}


	%\bibliographystyle{natbib}
	
	\def\spacingset#1{\renewcommand{\baselinestretch}%
		{#1}\small\normalsize} \spacingset{1}
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\if1\blind
	{
		\title{\bf Probabilistic Forecasts for Hierarchical~Time~Series}
		        \author{Puwasala Gamakumara\thanks{
		        The authors gratefully acknowledge the support of Australian Research Council Grant DP140103220.  We also thank Professor Mervyn Silvapulle for valuable comments.}\hspace{.2cm}\\
			    Department of Econometrics and Business Statistics,\\
			    Monash University,\\ VIC 3800, Australia.\\
			    Email: Puwasala.Gamakumara@monash.edu \\
			    and \\
			    Anastasios Panagiotelis\\
			    Department of Econometrics and Business Statistics,\\
		    	Monash University,\\ VIC 3800, Australia.\\
			    Email: Anastasios.Panagiotelis@monash.edu \\
			    and \\
		        George Athanasopoulos\\
		        Department of Econometrics and Business Statistics,\\
		        Monash University,\\ VIC 3800, Australia.\\
		        Email: george.athanasopoulos@monash.edu \\
		        and \\
	            Rob J Hyndman\\
	            Department of Econometrics and Business Statistics,\\
	            Monash University,\\ VIC 3800, Australia.\\
	            Email: rob.hyndman@monash.edu \\}
		\maketitle
	} \fi
	
	\if0\blind
	{
		\bigskip
		\bigskip
		\bigskip
		\begin{center}
			{\LARGE\bf Probabilistic Forecasts for Hierarchical~Time~Series}
		\end{center}
		\medskip
	} \fi
	
	\bigskip


\section{Supplementary material}

\subsection{Simulation study - under Gaussian assumptions}\label{sec:gaussian}

This simulation study was designed to compare different reconciliation methods assuming the data is conditionally Gaussian. We choose the Gaussian case due to its analytical tractability which allows for evaluation using all scoring rules (including the log score). The non-Gaussian case lies beyond the scope of this simulation study.

For the data generating process, we consider the hierarchy given in Figure~\ref{fig1}, comprising two aggregation levels with four bottom-level series. Each bottom-level series will be generated first, and then summed to obtain the data for the upper-level series. In practice, hierarchical time series tend to contain much noisier series at lower levels of aggregation. In order to replicate this feature in our simulations, we follow the data generating process proposed by \citet{Wickramasuriya2017}.

First $\{w_{AA,t},w_{AB,t},w_{BA,t},w_{BB,t}\}$ are generated from ARIMA$(p,d,q)$ processes, where $(p,q)$ and $d$ take integers from $\{1,2\}$ and $\{0,1\}$ respectively with equal probability. The errors driving these ARIMA processes are jointly normal, and denoted by $\{\varepsilon_{AA,t},\varepsilon_{AB,t},\varepsilon_{BA,t},\varepsilon_{BB,t}\} \overset{iid}{\sim} \mathcal{N}(\bm{0}, \bm{\Sigma})~\forall t$. The parameters for the AR and MA components are randomly and uniformly generated from $[0.3,0.5]$ and $[0.3,0.7]$ respectively. Then the bottom-level series $\{y_{AA,t},y_{AB,t},y_{BA,t},y_{BB,t}\}$ are given by:
\begin{align*}
y_{AA,t} &= w_{AA,t} + u_t - 0.5v_t,\\
y_{AB,t} &= w_{AB,t} - u_t - 0.5v_t,\\
y_{BA,t} &= w_{BA,t} + u_t + 0.5v_t,\\
y_{BB,t} &= w_{BB,t} - u_t + 0.5v_t,
\end{align*}
where $u_t \sim \mathcal{N}(0,\sigma^2_u)$ and $v_t \sim \mathcal{N}(0,\sigma^2_v)$. The aggregate series in the middle-level are given by:
\begin{align*}
y_{A,t} &= w_{AA,t} + w_{AB,t} - v_t,\\
y_{B,t} &= w_{BA,t} + w_{BB,t} + v_t,
\end{align*}
and the total series is given by
\[
  y_{Tot,t} = w_{AA,t} + w_{AB,t} + w_{BA,t} + w_{BB,t}.
\]
To ensure the disaggregate series are noisier than the aggregate series, we choose $\bm{\Sigma}, \sigma^2_u$ and $\sigma^2_v$ such that
\[
  \var(\varepsilon_{AA,t} + \varepsilon_{AB,t} + \varepsilon_{BA,t} + \varepsilon_{BB,t})
  \le \var(\varepsilon_{AA,t}+\varepsilon_{AB,t}-v_t)
  \le \var(\varepsilon_{AA,t}+u_t-0.5v_t)\,,
\]
and similar inequalities hold when $\varepsilon_{AA,t}$ is replaced by $\varepsilon_{AB,t}$, $\varepsilon_{BA,t}$ and $\varepsilon_{BB,t}$ in the third term.
The values of $\bm{\Sigma}$, $\sigma^2_u$ and $\sigma^2_v$ that we use and which satisfy these constraints are $\sigma^2_u = 19$, $\sigma^2_u = 18$ and
\[
\bm{\Sigma} =
\begin{pmatrix}
5.0 & 3.1 & 0.6 & 0.4 \\
3.1 & 4.0 & 0.9 & 1.4 \\
0.6 & 0.9 & 2.0 & 1.8 \\
0.4 & 1.4 & 1.8 & 3.0 \\
\end{pmatrix}\,.
\]

We generate data with a sample size of $T=501$. Univariate ARIMA models are selected for each series using the \textit{auto.arima} function in the \textit{forecast} package \citep{hyndman2017forecasting} in R \citep{Rcore}. The same package was used to fit each series independently using the first 500 observations, and evaluate 1-step ahead base (incoherent) probabilistic forecasts. These were then reconciled using different projections summarised in Table~\ref{table:2}. This process was replicated using $1000$ different data sets from the same data generating processes.

To assess the predictive performance of different forecasting methods, we use scoring rules as discussed in Section~\ref{sec:evaluation}. To facilitate comparisons, we report skill scores \citep{Gneiting2007}. For a given forecasting method, evaluated by a particular scoring rule, the skill score 
gives the percentage improvement of the preferred forecasting method relative to a reference method. A negative valued skill score indicates that a method is worse than the reference method, whereas any positive value indicates that the method is superior to the reference method.

Table~\ref{table:3} summarizes the forecasting performance of unreconciled, bottom-up, OLS, WLS and two MinT reconciliation methods using log score, energy score and variogram score. In all cases skill scores are calculated with the bottom-up method as reference. All log scores are evaluated on the basis of bottom-level series only, however these only differ from the log scores for the full hierarchy by a fixed constant. The cell for log score of unreconciled forecasts is left blank since the log score is not proper in this context. Overall, the MinT methods provide the best performance irrespective of the scoring rule, and all methods that reconcile using information at all levels of the forecast improve upon unreconciled forecasts. Bottom-up forecasts perform even worse than unreconciled forecasts in some cases.

Tables~\ref{table:4} and~\ref{table:5} break down the forecasting performance of different reconciliation methods by considering univariate scores on each individual margin.  Tables~\ref{table:4} summarises results for the top and middle-level, Table~\ref{table:5} does the same for bottom-level. The log score and CRPS are considered, while skill scores are computed with the unreconciled forecast as a reference. When broken down in this fashion, the methods based on MinT perform best for all series and always outperform bottom-up and unreconciled forecasts.

\begin{table}
	\caption{Comparison of coherent forecasts. ``Energy score'' and ``Variogram score'' columns give scores based on the joint forecast distribution of the whole hierarchy. ``Log score'' column gives the log scores of the joint forecast distribution of the bottom-level. ``Skill score'' columns give the percentage skill score with reference to the bottom-up method. Entries in these columns show the percentage increase of scores for different reconciliation methods relative to the bottom-up method.}\label{table:3}

	\centering\small
	\begin{tabular}{@{}lSSSSSS@{}}
		\toprule
		Forecasting &
		\multicolumn{2}{c}{\text{Energy score}} &
		\multicolumn{2}{c}{\text{Variogram score}} &
		\multicolumn{2}{c}{\text{Log score}} \\
		\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(l){6-7}
		method &
		\text{Mean score} & \text{Skill score \%} &
		\text{Mean score} & \text{Skill score \%} &
		\text{Mean score} & \text{Skill score \%}\\
		\midrule
		MinT(Shrink) &  10.03 & 18.79  & 8.44  & 8.46 & 11.30 &  6.22 \\
		MinT(Sample) &  10.01 & 18.95  & 8.41  & 8.79 & 11.29 &  6.31 \\
		MinT(WLS)    &  10.53 & 14.74  & 9.02  & 2.17 & 12.61 & -4.65 \\
		OLS          &  10.53 & 14.74  & 8.86  & 3.09 & 11.54 &  4.23\\
		Bottom-up    &  12.35 &    	   & 9.22  &      & 12.05 &  \\
		Incoherent	 &  11.12 &   	   & 9.53  &      &       &  \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}
	\caption{Comparison of incoherent vs coherent forecasts based on the univariate forecast distribution of aggregate series. The ``Incoherent'' row shows the average scores for incoherent forecasts. Each entry above this row represents the percentage skill score with reference to the incoherent forecasts. These entries show the percentage increase in score for different forecasting methods relative to the incoherent forecasts.}\label{table:4}
	\centering\small
	\begin{tabular}{@{}lSSSSSS@{}}
		\toprule
		Forecasting &
		\multicolumn{2}{c}{\text{Total}} &
		\multicolumn{2}{c}{\text{Series - A}} &
		\multicolumn{2}{c}{\text{Series - B}} \\
		\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(l){6-7}
		method      &  CRPS   & LogS    & CRPS   & LogS     & CRPS   & LogS     \\
		\midrule
		MinT(Shrink) &   0.74  &   0.00   & 10.49   &  3.24  &  9.16  &  2.73    \\
		MinT(Sample) &   0.74  &   0.00   & 10.49   &  3.24  &  9.16  &  2.73    \\
		MinT(WLS)    &  -2.96  &  -2.36   &  6.10   & -4.12  &  5.66  & -3.03    \\
		OLS          &  -9.26  &  -3.36   &  7.07   &  2.06  &  7.01  &  1.82    \\
		Bottom-up    & -91.48  & -22.22   & -8.05   & -2.06  & -6.20  & -1.82    \\
		\midrule
		\textit{Incoherent} & $\mathbi{2.70}$ & $\mathbi{2.97}$ & $\mathbi{4.10}$ & $\mathbi{3.40}$ & $\mathbi{3.71}$ & $\mathbi{3.30}$ \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}
	\caption{Comparison of incoherent vs coherent forecasts based univariate forecast distribution of bottom-level series. The ``Incoherent'' row shows the average scores for incoherent forecasts.}\label{table:5}
	\centering\tabcolsep=0.08cm\small
	\begin{tabular}{@{}lSSSSSSSS@{}}
		\toprule
		Forecasting &
		\multicolumn{2}{c}{\text{Series - AA}} &
		\multicolumn{2}{c}{\text{Series - AB}} &
		\multicolumn{2}{c}{\text{Series - BA}} &
		\multicolumn{2}{c}{\text{Series - BB}} \\
		\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(l){8-9}
		method       & CRPS   & LogS    & CRPS   & LogS    & CRPS   & LogS    & CRPS   & LogS \\
		\midrule
		MinT(Shrink) &  7.61  &  2.43  &  10.82  &  3.02  &  5.93  &  1.86  &  7.76  & 2.47  \\
		MinT(Sample) &  7.88  &  2.43  &  11.08  &  3.02  &  6.20  &  1.86  &  8.05  & 2.47  \\
		MinT(WLS)    &  3.53  &  0.00  &   6.33  &  0.60  &  2.43  & -0.62  &  4.89  & 0.62  \\
		OLS          &  2.99  &  0.91  &   5.28  &  1.51  &  2.90  &  0.62  &  4.31  & 1.23  \\
		\midrule
		\textit{Incoherent} & $\mathbi{3.68}$ & $\mathbi{3.29}$ & $\mathbi{3.79}$ & $\mathbi{3.31}$ & $\mathbi{3.45}$ & $\mathbi{3.22}$ & $\mathbi{3.48}$ & $\mathbi{3.24}$ \\
		\bottomrule
	\end{tabular}
\end{table}



\newpage

\bibliographystyle{agsm}

\bibliography{References_paper1}

\end{document}

