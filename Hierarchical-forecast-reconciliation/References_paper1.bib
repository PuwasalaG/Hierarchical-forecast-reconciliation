@article{Dunn1976,
abstract = {Should statistical forecasts be constructed by aggregating data to each level for which forecasts are required or aggregating the forecasts from the lower levels? The relevant literature suggests no general answer. In this study using actual data, forecasts aggregated from lower-level modeling were found best.},
author = {Dunn, D M and Williams, W H and Dechaine, T L},
doi = {10.2307/2285732},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dunn, Williams, Dechaine - 1976 - Aggregate Versus Subaggregate Models in Local Area Forecasting.pdf:pdf},
isbn = {0162-1459},
issn = {1537274X},
journal = {Journal of American Statistical Association},
number = {353},
pages = {68--71},
title = {Aggregate Versus Subaggregate Models in Local Area Forecasting},
volume = {71},
year = {1976}
}
@article{taylor1986retransformed,
  title={The retransformed mean after a fitted power transformation},
  author={Taylor, Jeremy MG},
  journal={Journal of the American Statistical Association},
  volume={81},
  number={393},
  pages={114--118},
  year={1986},
  publisher={Taylor \& Francis Group}
}

@article{Schwarzkopf1988,
  title={Top-down versus bottom-up forecasting strategies},
  author={Schwarzkopf, Albert B and Tersine, Richard J and Morris, John S},
  journal={International Journal of Production Research},
  volume={26},
  number={11},
  pages={1833--1843},
  year={1988},
  publisher={Taylor \& Francis}
}
@article{Gross1990,
abstract = {This paper addresses the issue of forecasting individual items within a product line; where each line includes several independent but closely related products. The purpose of the research was to reduce the overall forecasting burden by developing and assessing schemes of disaggregating forecasts of a total product line to the related individual items. Measures were developed to determine appropriate disaggregated methodologies and to compare the forecast accuracy of individual product forecasts versus disaggregated totals. Several of the procedures used were based upon extensions of the combination of forecast research and applied to disaggregations of total forecasts of product lines. The objective was to identify situations when it was advantageous to produce disaggregated forecasts, and if advantageous, which method of disaggregation to utilize. This involved identification of the general conceptual characteristics within a set of product line data that might cause a disaggregation method to produce relatively accurate forecasts. These conceptual characteristics provided guidelines for forecasters on how to select a disaggregation method and under what conditions a particular method is applicable.},
author = {Gross, Charles W. and Sohl, Jeffrey E.},
doi = {10.1002/for.3980090304},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gross, Sohl - 1990 - Disaggregation methods to expedite product line forecasting.pdf:pdf},
isbn = {1099-131X},
issn = {1099131X},
journal = {Journal of Forecasting},
keywords = {Composite root mean square error differential,Disaggregational methods,Forecasting,Product line,Time series analysis},
number = {3},
pages = {233--254},
title = {Disaggregation methods to expedite product line forecasting},
volume = {9},
year = {1990}
}

@article{Kahn1998,
  title={Revisiting top-down versus bottom-up forecasting},
  author={Kahn, Kenneth B},
  journal={The Journal of Business Forecasting},
  volume={17},
  number={2},
  pages={14},
  year={1998},
  publisher={Journal of Business Forecasting}
}
@article{Lapide1998,
author = {Lapide, Larry},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lapide - 1998 - A simple view of top-down vs bottom-up forecasting.pdf.pdf:pdf},
journal = {Journal of Business Forecasting Methods {\&} Systems},
pages = {28--31},
title = {A simple view of top-down vs bottom-up forecasting},
volume = {17},
year = {1998}
}

@article{Fliedner2001,
abstract = {In order to provide the appropriate demand forecast information given various managerial levels and functional disciplines within organizations, reliance on family-based forecasting is increasing. The family-based approach, sometimes referred to as hierarchical forecasting (HF), is based on a strategy of aggregating items into families. HF systems are capable of providing forecasts for items and their respective families. The objectives of HF systems, include improved forecast performance and a reduction in the overall forecasting burden. To date, several studies have offered practical guidelines for the structural design of HF systems. The primary purpose of this paper is to summarize these guidelines. First, an explanation of the HF process is provided. In this explanation, important system parameters and strategic choices, which allow for the custom configuration of HF systems are identified. Second, the relevant family-based forecast research is reviewed. The important issues addressed and the conclusions presented in this research are identified. Third, practical guidelines regarding the use of a HF approach that have been reported in the research literature are clearly delineated. With much still unknown regarding the performance impact of various system parameter and strategic process choices, the paper concludes with suggestions for future research.},
author = {Fliedner, Gene},
doi = {10.1108/02635570110365952},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fliedner - 2001 - Hierarchical forecasting issues and use guidelines.pdf:pdf},
isbn = {1463577001},
issn = {0263-5577},
journal = {Industrial Management {\&} Data Systems},
keywords = {forecasting,hierarchy,product management,time series},
number = {1},
pages = {5--12},
title = {Hierarchical forecasting: issues and use guidelines},
volume = {101},
year = {2001}
}

@article{Abramson1995,
abstract = {applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Abramson, Bruce and Clemen, Robert},
doi = {10.1016/0169-2070(94)02000-F},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abramson, Clemen - 1995 - Probability forecasting.pdf:pdf},
isbn = {9788578110796},
issn = {01692070},
journal = {International Journal of Forecasting},
number = {1},
pages = {1--4},
pmid = {25246403},
title = {Probability forecasting},
volume = {11},
year = {1995}
}
@article{WicEtAl2019,
abstract = {AbstractLarge collections of time series often have aggregation constraints due to product or geographical groupings. The forecasts for the most disaggregated series are usually required to add-up exactly to the forecasts of the aggregated series, a constraint we refer to as “coherence”. Forecast reconciliation is the process of adjusting forecasts to make them coherent. The reconciliation algorithm proposed by Hyndman et al. (2011) is based on a generalized least squares estimator that requires an estimate of the covariance matrix of the coherency errors (i.e., the errors that arise due to incoherence). We show that this matrix is impossible to estimate in practice due to identifiability conditions. We propose a new forecast reconciliation approach that incorporates the information from a full covariance matrix of forecast errors in obtaining a set of coherent forecasts. Our approach minimizes the mean squared error of the coherent forecasts across the entire collection of time series under the assumption of unbiasedness. The minimization problem has a closed form solution. We make this solution scalable by providing a computationally efficient representation. We evaluate the performance of the proposed method compared to alternative methods using a series of simulation designs which take into account various features of the collected time series. This is followed by an empirical application using Australian domestic tourism data. The results indicate that the proposed method works well with artificial and real data.},
author = {Wickramasuriya, Shanika L. and Athanasopoulos, George and Hyndman, Rob J.},
doi = {10.1080/01621459.2018.1448825},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Wickramasuriya, Athanasopoulos, Hyndman - 2019 - Optimal Forecast Reconciliation for Hierarchical and Grouped Time Series Through Tra(2).pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Aggregation,Australian tourism,Coherent forecasts,Contemporaneous error correlation,Forecast combinations,Spatial correlations},
number = {526},
pages = {804--819},
publisher = {Taylor {\&} Francis},
title = {Optimal Forecast Reconciliation for Hierarchical and Grouped Time Series Through Trace Minimization},
volume = {114},
year = {2019}
}
@incollection{AthEtAl2019_MacroBook,
address = {Honolulu},
author = {Athanasopoulos, George and Gamakumara, Puwasala and Panagiotelis, Anastasios and Hyndman, Rob J and Affan, Mohamed},
booktitle = {Macroeconomic Forecasting in the Era of Big Data},
chapter = {21},
editor = {Peter Fuleky},
pages = {703--733},
publisher = {Springer},
title = {Hierarchical Forecasting},
year = {2019}
}
@Manual{Rforecast,
  title = {forecast: Forecasting Functions for Time Series and Linear Models},
  year = {2019},
  author = {Rob J Hyndman and George Athanasopoulos and Christoph Bergmeir and Gabriel Caceres and Leanne Chhay and Mitchell O'Hara-Wild and Fotios Petropoulos and Slava Razbash and Earo Wang and Farah Yasmeen and {R Core Team} and Ross Ihaka and Daniel Reid and David Shaub and Yuan Tang and Zhenyu Zhou},
  note = {Version 8.9}
  }

@article{guerrero1993time,
  title={Time-series analysis supported by power transformations},
  author={Guerrero, V{\'\i}ctor M},
  journal={Journal of Forecasting},
  volume={12},
  number={1},
  pages={37--48},
  year={1993},
  publisher={Wiley Online Library}
}

@book{FPP2018,
  title={Forecasting: principles and practice},
  author={Hyndman, Rob J and Athanasopoulos, George},
  year={2018},
  publisher={OTexts},
  edition = {2nd},
  address = {Melbourne, Australia}
  }

@article{rao1974,
  title={Projectors, generalized inverses and the {BLUE}'s},
  author={Rao, C Radhakrishna},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={36},
  number={3},
  pages={442--448},
  year={1974},
  publisher={Wiley Online Library}
}

@article{Tay2000,
abstract = {A density forecast of the realization of a random variable at some future time is an estimate of the probability distribution of the possible future values of that variable. This article presents a selective survey of applications of density forecasting in macroeconomics and finance, and discusses some issues concerning the production, presentation, and evaluation of density forecasts. Copyright (C) 2000 John Wiley {\&} Sons, Ltd.},
author = {Tay, Anthony S. and Wallis, Kenneth F.},
doi = {10.1002/9780470996430.ch3},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tay, Wallis - 2000 - Density forecasting A survey.pdf:pdf},
isbn = {9780470996430},
issn = {0277-6693},
journal = {Journal of Forecasting},
keywords = {Financial forecasts,density forecasts,economic forecasts,forecast evaluation,probability distributions},
pages = {124--143},
title = {Density forecasting: A survey},
volume = {19},
year = {2000}
}

@article{Gel2004,
abstract = {Probabilistic weather forecasting consists of finding a joint probability distribution for future weather quantities or events. It is typically done by using a numerical weather prediction model, perturbing the inputs to the model in various ways, and running the model for each perturbed set of inputs. The result is then viewed as an ensemble of forecasts, taken to be a sample from the joint probability distribution of the future weather quantities of interest. This is typically not feasible for mesoscale weather prediction carried out locally by organizations without the vast data and computing resources of national weather centers. Instead, we propose a simpler method that breaks with much previous practice by perturbing the outputs, or deterministic forecasts, from the model. Forecast errors are modeled using a geostatistical model, and ensemble members are generated by simulating realizations of the geostatistical model. The method is applied to 48-hour mesoscale forecasts of temperature in the North ...},
author = {Gel, Yulia and Raftery, Adrian E and Gneiting, Tilmann},
doi = {10.1198/016214504000000872},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gel, Raftery, Gneiting - 2004 - Calibrated Probabilistic Mesoscale Weather Field Forecasting.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {empirical calibration,ensemble forecast,geostatistical simulation,probabilistic weather prediction},
number = {July},
pages = {575--583},
title = {Calibrated Probabilistic Mesoscale Weather Field Forecasting},
volume = {99},
year = {2004}
}
@article{Schafer2005,
abstract = {{\textless}p{\textgreater}Inferring large-scale covariance matrices from sparse genomic data is an ubiquitous problem in bioinformatics. Clearly, the widely used standard covariance and correlation estimators are ill-suited for this purpose. As statistically efficient and computationally fast alternative we propose a novel shrinkage covariance estimator that exploits the Ledoit-Wolf (2003) lemma for analytic calculation of the optimal shrinkage intensity.Subsequently, we apply this improved covariance estimator (which has guaranteed minimum mean squared error, is well-conditioned, and is always positive definite even for small sample sizes) to the problem of inferring large-scale gene association networks. We show that it performs very favorably compared to competing approaches both in simulations as well as in application to real expression data.{\textless}/p{\textgreater}},
author = {Sch{\"{a}}fer, Juliane and Strimmer, Korbinian},
doi = {10.2202/1544-6115.1175},
file = {:C$\backslash$:/Puwasala/PhD{\_}Monash/Research/First year/Research papers/Covariance matrix adjustment/Covariance matrix estimation/shrinkage approach to large-scale covariance matrix estimation{\_}2005.pdf:pdf},
isbn = {1544-6115},
issn = {1544-6115},
journal = {Statistical Applications in Genetics and Molecular Biology},
number = {1},
pmid = {16646851},
title = {A Shrinkage Approach to Large-Scale Covariance Matrix Estimation and Implications for Functional Genomics},
volume = {4},
year = {2005}
}
@article{McSharry2005,
abstract = {Adequate capacity planning requires accurate forecasts of the future magnitude and timing of peak electricity demand. Electricity demand is affected by the day of the week, seasonal variations, holiday periods, feast days, and the weather. A model that provides probabilistic forecasts of both magnitude and timing for lead times of one year is presented. This model is capable of capturing the main sources of variation in demand and uses simulated weather time series, including temperature, wind speed, and luminosity, for producing probabilistic forecasts of future peak demand. Having access to such probabilistic forecasts provides a means of assessing the uncertainty in the forecasts and can lead to improved decision making and better risk management. {\&}copy; 2005 IEEE.},
author = {McSharry, Patrick E. and Bouwman, Sonja and Bloemhof, Gabri{\"{e}}l},
doi = {10.1109/TPWRS.2005.846071},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/McSharry, Bouwman, Bloemhof - 2005 - Probabilistic forecasts of the magnitude and timing of peak electricity demand.pdf:pdf},
isbn = {0885-8950},
issn = {08858950},
journal = {IEEE Transactions on Power Systems},
keywords = {Load forecasting,Load management,Management decision making,Power demand,Power generation peaking capacity,Power system planning,Simulation,Temperature,Time series},
number = {2},
pages = {1166--1172},
title = {Probabilistic forecasts of the magnitude and timing of peak electricity demand},
volume = {20},
year = {2005}
}
@article{Gneiting2005,
author = {Gneiting, Tilmann and Raftery, Andrian E.},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gneiting, Raftery - 2005 - Weather{\_}forecasting{\_}with{\_}ensem.PDF.pdf:pdf},
journal = {Science},
pages = {248--249},
title = {Weather forecasting with ensemble methods},
volume = {310.5746},
year = {2005}
}
@article{Gneiting2005a,
abstract = {Ensemble prediction systems typically show positive spread-error correlation, but they are subject to forecast bias and dispersion errors, and are therefore uncalibrated. This work proposes the use of ensemble model output statistics (EMOS), an easy-to-implement postprocessing technique that addresses both forecast bias and underdispersion and takes into account the spread-skill relationship. The technique is based on multiple linear regression and is akin to the superensemble approach that has traditionally been used for deterministic-style forecasts. The EMOS technique yields probabilistic forecasts that take the form of Gaussian predictive probability density functions (PDFs) for continuous weather variables and can be applied to gridded model output. The EMOS predictive mean is a bias-corrected weighted average of the ensemble member forecasts, with coefficients that can be interpreted in terms of the relative contributions of the member models to the ensemble, and provides a highly competitive deterministic-style forecast. The EMOS predictive variance is a linear function of the ensemble variance. For fitting the EMOS coefficients, the method of minimum continuous ranked probability score (CRPS) estimation is introduced. This technique finds the coefficient values that optimize the CRPS for the training data. The EMOS technique was applied to 48-h forecasts of sea level pressure and surface temperature over the North American Pacific Northwest in spring 2000, using the University of Washington mesoscale ensemble. When compared to the bias-corrected ensemble, deterministic-style EMOS forecasts of sea level pressure had root-mean-square error 9{\%} less and mean absolute error 7{\%} less. The EMOS predictive PDFs were sharp, and much better calibrated than the raw ensemble or the bias-corrected ensemble.},
author = {Gneiting, Tilmann and Raftery, Adrian E. and Westveld, Anton H. and Goldman, Tom},
doi = {10.1175/MWR2904.1},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gneiting et al. - 2005 - Calibrated Probabilistic Forecasting Using Ensemble Model Output Statistics and Minimum CRPS Estimation.pdf:pdf},
issn = {0027-0644},
journal = {Monthly Weather Review},
number = {5},
pages = {1098--1118},
title = {Calibrated Probabilistic Forecasting Using Ensemble Model Output Statistics and Minimum {CRPS} Estimation},
volume = {133},
year = {2005}
}
@article{Yao2006,
abstract = {Abstract.  We provide a direct proof for consistency and asymptotic normality of Gaussian maximum likelihood estimators for causal and invertible autoregressive moving-average (ARMA) time series models, which were initially established by Hannan [Journal of Applied Probability (1973) vol. 10, pp. 130–145] via the asymptotic properties of a Whittle's estimator. This also paves the way to establish similar results for spatial processes presented in the follow-up article by Yao and Brockwell [Bernoulli (2006) in press].},
author = {Yao, Qiwei and Brockwell, Peter J.},
doi = {10.1111/j.1467-9892.2006.00492.x},
file = {:C$\backslash$:/Puwasala/PhD{\_}Monash/Research/Second year/Literature review/Time series analysis/Gaussian MLE for ARMA models.pdf:pdf},
isbn = {1467-9892},
issn = {01439782},
journal = {Journal of Time Series Analysis},
keywords = {ARMA time series models,Asymptotic normality,Consistency,Gaussian maximum likelihood estimator,Innovation algorithm,Martingale difference,Prewhitening},
number = {6},
pages = {857--875},
title = {Gaussian maximum likelihood estimation for {ARMA} models. {I.} {Time} series},
volume = {27},
year = {2006}
}
@article{Gneiting2006,
abstract = {With the global proliferation of wind power, the need for accurate short-term forecasts of wind resources at wind energy sites is becoming paramount. Regime-switching space-time (RST) models merge meteorological and statistical expertise to obtain accurate and calibrated, fully probabilistic forecasts of wind speed and wind power. The model formulation is parsimonious, yet takes into account all of the salient features of wind speed: alternating atmospheric regimes, temporal and spatial correlation, diurnal and seasonal nonstationarity, conditional heteroscedasticity, and non-Gaussianity. The RST method identifies forecast regimes at a wind energy site and fits a conditional predictive model for each regime. Geographically dispersed meteorological observations in the vicinity of the wind farm are used as off-site predictors. The RST technique was applied to 2-hour-ahead forecasts of hourly average wind speed near the Stateline wind energy center in the U.S. Pacific Northwest. The RST point forecasts and distributional forecasts were accurate, calibrated, and sharp, and they compared favorably with predictions based on state-of-the-art time series techniques. This suggests that quality meteorological data from sites upwind of wind farms can be efficiently used to improve short-term forecasts of wind resources.},
author = {Gneiting, Tilmann and Larson, Kristin and Westrick, Kenneth and Genton, Marc G and Aldrich, Eric},
doi = {10.1198/016214506000000456},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gneiting et al. - 2006 - Calibrated Probabilistic Forecasting at the Stateline Wind Energy Center.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {continuous ranked probability score,minimum continuous ranked probability,predictive distribution,score estimation,spatiotemporal,truncated normal,weather prediction},
number = {475},
pages = {968--979},
title = {Calibrated Probabilistic Forecasting at the Stateline Wind Energy Center},
volume = {101},
year = {2006}
}
@article{Hall2007,
abstract = {This paper brings together two important but hitherto largely unrelated areas of the forecasting literature, density forecasting and forecast combination. It proposes a practical data-driven approach to the direct combination of density forecasts by taking a weighted linear combination of the competing density forecasts. The combination weights are chosen to minimize the 'distance', as measured by the Kullback-Leibler information criterion, between the forecasted and true but unknown density. We explain how this minimization both can and should be achieved but leave theoretical analysis to future research. Comparisons with the optimal combination of point forecasts are made. An application to simple time-series density forecasts and two widely used published density forecasts for U.K. inflation, namely the Bank of England and NIESR "fan" charts, illustrates that combination can but need not always help. {\textcopyright} 2006 International Institute of Forecasters.},
author = {Hall, Stephen G. and Mitchell, James},
doi = {10.1016/j.ijforecast.2006.08.001},
file = {:C$\backslash$:/Puwasala/PhD{\_}Monash/Research/Second year/Literature review/Minimizing log score/Combining density forecasts.pdf:pdf},
isbn = {0169-2070},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Combining forecasts,Density forecasts,Evaluating forecasts,Inflation forecasting,Uncertainty},
number = {1},
pages = {1--13},
title = {Combining density forecasts},
volume = {23},
year = {2007}
}
@article{Pinson2009,
abstract = {Short-term (up to 2-3 days ahead) probabilistic forecasts of wind power provide forecast users with a highly valuable information on the uncertainty of expected wind generation. Whatever the type of these probabilistic forecasts, they are produced on a per horizon basis, and hence do not inform on the devel- opment of the forecast uncertainty through forecast series. However, this additional informationmay be paramount for a large class of time-dependent and multi-stage decision-making problems e.g. optimal operation of combined wind-storage systems or multiple-market trading with different gate closures. This issue is addressed here by describing amethod that permits the generation of statistical scenarios of short-termwind generation that accounts for both the interdependence structure of prediction errors and the predictive distributions of wind power production. The method is based on the conversion of series of prediction errors to a multivariate Gaussian random variable, the interdependence structure of which can then be summarized by a unique covariance matrix. Such matrix is recursively estimated in order to accommodate long-term variations in the prediction error characteristics. The quality and interest of the methodology are demonstrated with an application to the test case of a multi-MWwind farm over a period of more than two years. Keywords:},
author = {Pinson, Pierre and Madsen, Henrik and Papaefthymiou, George and Kl{\"{o}}ckl, Bernd},
doi = {10.1002/we.284},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pinson et al. - 2009 - From Probabilistic Forecasts to Wind Power Production.pdf:pdf},
issn = {10954244},
journal = {Wind Energy},
keywords = {forecasting,multivariate Gaussian random variable,scenarios,uncertainty,wind power},
number = {1},
pages = {51--62},
title = {From Probabilistic Forecasts to Wind Power Production},
volume = {12},
year = {2009}
}
@article{Hyndman2011,
abstract = {In many applications, there are multiple time series that are hierarchically organized and can be aggregated at several different levels in groups based on products, geography or some other features. We call these "hierarchical time series". They are commonly forecast using either a "bottom-up" or a "top-down" method. In this paper we propose a new approach to hierarchical forecasting which provides optimal forecasts that are better than forecasts produced by either a top-down or a bottom-up approach. Our method is based on independently forecasting all series at all levels of the hierarchy and then using a regression model to optimally combine and reconcile these forecasts. The resulting revised forecasts add up appropriately across the hierarchy, are unbiased and have minimum variance amongst all combination forecasts under some simple assumptions. We show in a simulation study that our method performs well compared to the top-down approach and the bottom-up method. We demonstrate our proposed method by forecasting Australian tourism demand where the data are disaggregated by purpose of travel and geographical region. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
author = {Hyndman, Rob J. and Ahmed, Roman A. and Athanasopoulos, George and Shang, Han Lin},
doi = {10.1016/j.csda.2011.03.006},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hyndman et al. - 2011 - Optimal combination forecasts for hierarchical time series.pdf:pdf},
isbn = {0167-9473},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Bottom-up forecasting,Combining forecasts,GLS regression,Hierarchical forecasting,Reconciling forecasts,Top-down forecasting},
number = {9},
pages = {2579--2589},
publisher = {Elsevier B.V.},
title = {Optimal combination forecasts for hierarchical time series},
volume = {55},
year = {2011}
}
@article{Szekely2013,
abstract = {Energy distance is a statistical distance between the distributions of random vectors, which characterizes equality of distributions. The name energy derives from Newton's gravitational potential energy, and there is an elegant relation to the notion of potential energy between statistical observations. Energy statistics are functions of distances between statistical observations in metric spaces. Thus even if the observations are complex objects, like functions, one can use their real valued nonnegative distances for inference. Theory and application of energy statistics are discussed and illustrated. Finally, we explore the notion of potential and kinetic energy of goodness-of-fit. {\textcopyright} 2013 Elsevier B.V.},
author = {Sz{\'{e}}kely, G{\'{a}}bor J. and Rizzo, Maria L.},
doi = {10.1016/j.jspi.2013.03.018},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sz{\'{e}}kely, Rizzo - 2013 - Energy statistics A class of statistics based on distances.pdf:pdf},
isbn = {03783758},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Distance correlation,Distance covariance,Energy distance,Goodness-of-fit,Multivariate independence},
number = {8},
pages = {1249--1272},
publisher = {Elsevier},
title = {Energy statistics: A class of statistics based on distances},
volume = {143},
year = {2013}
}
@techreport{Pinson2013a,
abstract = {Research on generating and verification of multivariate probabilistic forecasts has gained increased interest over the last few years. Emphasis is placed here on the evaluation of forecast quality with the Energy score, which is based on a quadratic scoring rule. While this score may be seen as appealing since being proper, we show that its discrimination ability may be limited when focusing on the dependence structure of multivariate probabilistic forecasts. For the case of multivariate Gaussian process, a theoretical upper for such discrimination ability is derived and discussed. This limited discrimination ability may eventually get compromised by computational and sampling issues, as dimension increases.},
author = {Pinson, P and Tastu, Julija},
institution = {Technical University of Denmark.},
keywords = {Discrimination,Energy score,Multivariate scenarios BT - Discrimination ability,Probabilistic forecasting,Proper score},
title = {Discrimination ability of the Energy score},
year = {2013}
}
@article{Vilar2013,
abstract = {Smart electricity meters are currently deployed in millions of households to collect detailed individual electricity consumption data. Compared to traditional electricity data based on aggregated consumption, smart meter data are much more volatile and less predictable. There is a need within the energy industry for probabilistic forecasts of household electricity consumption to quantify the uncertainty of future electricity demand, in order to undertake appropriate planning of generation and distribution. We propose to estimate an additive quantile regression model for a set of quantiles of the future distribution using a boosting procedure. By doing so, we can benefit from flexible and interpretable models which include an automatic variable selection. We compare our approach with three benchmark methods on both aggregated and disaggregated scales using a smart meter dataset collected from 3639 households in Ireland at 30-minute intervals over a period of 1.5 years. The empirical results demonstrate that our approach based on quantile regression provides better forecast accuracy for disaggregated demand while the traditional approach based on a normality assumption (possibly after an appropriate Box- Cox transformation) is a better approximation for aggregated demand. These results are particularly useful since more energy data will become available at the disaggregated level in the future. I. INTRODUCTION T HE energy sector has been changing dramatically, notably due to the integration of renewable energy sources, in an effort to reduce our dependency on fossil fuels and achieve a better sustainable future. With the growing amount of data from energy systems, there is a need for utilities to quantify the uncertainty in future generation and demand, especially for wind power [1], solar power [2] and electricity demand [3]. In particular, accurate probabilistic forecasts for electricity demand are critical for electric utilities in many operational and planning tasks. Electricity load is often represented as the aggregated load across many households (e.g. at the city level). There is also a rich literature on forecasting the average aggregated electricity load; i.e. in forecasting the mean of the future demand distribution. These forecasts are often conditional on a number of predictor variables such as calendar and temperature variables. Many models have been considered S. BenTaieb is with the King Abdullah University of Science and Tech- nology (KAUST), Thuwal, Saudi Arabia, and the Monash Business School, Clayton, VIC 3800, Australia (e-mails: souhaib.bentaieb@monash.edu). R. Huser is with the King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia (e-mail: raphael.huser@kaust.edu.sa). R. J. Hyndman is with the Monash Business School, Clayton, VIC 3800, Australia (e-mail: rob.hyndman@monash.edu). M. G. Genton is with the King Abdullah University of Science and Tech- nology (KAUST), Thuwal, Saudi Arabia (e-mail: marc.genton@kaust.edu.sa). for},
author = {Vilar, Jos{\'{e}} A. and Vilar, J. A.},
doi = {10.1109/TSG.2016.2527820},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ben Taieb et al. - 2016 - Forecasting uncertainty in electricity smart meter data by boosting additive quantile regression.pdf:pdf},
issn = {19493053},
journal = {Electronic Journal of Statistics},
keywords = {Probabilistic load forecasting,gradient boosting,quantile regression,smart meters},
number = {5},
pages = {1019--1046},
title = {Forecasting uncertainty in electricity smart meter data by boosting additive quantile regression},
volume = {7},
year = {2013}
}
@article{SCHEUERER2015,
author = {Scheuerer, Michael and Hamill, Thomas M.},
doi = {10.1175/MWR-D-14-00269.1},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Scheuerer, Hamill - 2015 - Variogram-Based Proper Scoring Rules for Probabilistic Forecasts of Multivariate Quantities.pdf:pdf},
journal = {Monthly Weather Review},
number = {4},
pages = {1321--1334},
title = {Variogram-Based Proper Scoring Rules for Probabilistic Forecasts of Multivariate Quantities},
volume = {143},
year = {2015}
}
@article{Hyndman2016,
abstract = {It is shown that the least squares approach to reconciling hierarchical time series forecasts can be extended to much more general collections of time series with aggregation constraints. The constraints arise due to the need for forecasts of collections of time series to add up in the same way as the observed time series. It is also shown that the computations involved can be handled efficiently by exploiting the structure of the associated design matrix, or by using sparse matrix routines. The proposed algorithms make forecast reconciliation feasible in business applications involving very large numbers of time series.},
author = {Hyndman, Rob J. and Lee, Alan J. and Wang, Earo},
doi = {10.1016/j.csda.2015.11.007},
file = {:C$\backslash$:/Puwasala/PhD{\_}Monash/Research/Confirmation/Lit review/Point and interval forecasts/Fast computation of reconciled forecasts for hierarchical and grouped time series.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Combining forecasts,Grouped time series,Hierarchical time series,Reconciling forecasts,Weighted least squares},
pages = {16--32},
publisher = {Elsevier B.V.},
title = {Fast computation of reconciled forecasts for hierarchical and grouped time series},
volume = {97},
year = {2016}
}
@article{Shang2017,
abstract = {Age-specific mortality rates are often disaggregated by different attributes, such as sex, state and ethnicity. Forecasting age-specific mortality rates at the national and sub-national levels plays an important role in developing social policy. However, independent forecasts at the sub-national levels may not add up to the forecasts at the national level. To address this issue, we consider reconciling forecasts of age-specific mortality rates, extending the methods of Hyndman et al. (2011) to functional time series, where age is considered as a continuum. The grouped functional time series methods are used to produce point forecasts of mortality rates that are aggregated appropriately across different disaggregation factors. For evaluating forecast uncertainty, we propose a bootstrap method for reconciling interval forecasts. Using the regional age-specific mortality rates in Japan, obtained from the Japanese Mortality Database, we investigate the one- to ten-step-ahead point and interval forecast accuracies between the independent and grouped functional time series forecasting methods. The proposed methods are shown to be useful for reconciling forecasts of age-specific mortality rates at the national and sub-national levels. They also enjoy improved forecast accuracy averaged over different disaggregation factors. Supplemental materials for the article are available online.},
archivePrefix = {arXiv},
arxivId = {1609.04222},
author = {Shang, Han Lin and Hyndman, Rob J.},
doi = {10.1080/10618600.2016.1237877},
eprint = {1609.04222},
file = {:C$\backslash$:/Puwasala/PhD{\_}Monash/Research/Confirmation/Lit review/Point and interval forecasts/Grouped functional time series forecasting{\_}an application to age specific mortality rates.pdf:pdf},
isbn = {6126125053},
issn = {15372715},
journal = {Journal of Computational and Graphical Statistics},
keywords = {Bottom-up,Forecast reconciliation,Hierarchical time series forecasting,Japanese mortality database,Optimal combination},
number = {2},
pages = {330--343},
title = {Grouped Functional Time Series Forecasting: An Application to Age-Specific Mortality Rates},
volume = {26},
year = {2017}
}
@article{Athanasopoulos2009,
abstract = {In this paper we explore the hierarchical nature of tourism demand time series and produce short-term forecasts for Australian domestic tourism. The data and forecasts are organized in a hierarchy based on disaggregating the data according to geographical regions and purposes of travel. We consider five approaches to hierarchical forecasting: two variations of the top-down approach, the bottom-up method, a newly proposed top-down approach where top-level forecasts are disaggregated according to the forecasted proportions of lower level series, and a recently proposed optimal combination approach. Our forecast performance evaluation shows that the top-down approach based on forecast proportions and the optimal combination method perform best for the tourism hierarchies we consider. By applying these methods, we produce detailed forecasts of the Australian domestic tourism market.},
author = {Athanasopoulos, George and Ahmed, Roman A. and Hyndman, Rob J.},
doi = {10.1016/J.IJFORECAST.2008.07.004},
issn = {0169-2070},
journal = {International Journal of Forecasting},
month = {jan},
number = {1},
pages = {146--166},
publisher = {Elsevier},
title = {Hierarchical forecasts for {Australian} domestic tourism},
volume = {25},
year = {2009}
}

@incollection{VanErven2015a,
  title={Game-theoretically optimal reconciliation of contemporaneous hierarchical time series forecasts},
  author={Van Erven, Tim and Cugliari, Jairo},
  booktitle={Modeling and Stochastic Learning for Forecasting in High Dimensions},
  pages={297--317},
  year={2015},
  publisher={Springer}
}
@article{Gneiting2014,
abstract = {Aprobabilistic forecast takes the form of a predictive probability distribution over future quantities or events of interest. Probabilistic forecasting aims to maximize the sharpness of the predictive distributions, subject to calibra- tion, on the basis of the available information set. We formalize and study notions of calibration in a prediction space setting. In practice, probabilis- tic calibration can be checked by examining probability integral transform (PIT) histograms. Proper scoring rules such as the logarithmic score and the continuous ranked probability score serve to assess calibration and sharp- ness simultaneously. As a special case, consistent scoring functions provide decision-theoretically coherent tools for evaluating point forecasts.We em- phasizemethodological links to parametric and nonparametric distributional regression techniques, which attempt to model and to estimate conditional distribution functions; we use the context of statistically postprocessed en- semble forecasts in numerical weather prediction as an example. Through- out, we illustrate concepts and methodologies in data examples. 125},
author = {Gneiting, Tilmann and Katzfuss, Matthias},
doi = {10.1146/annurev-statistics-062713-085831},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gneiting, Katzfuss - 2014 - Probabilistic Forecasting.pdf:pdf},
isbn = {978-0-8243-3950-0},
issn = {2326-8298},
journal = {Annual Review of Statistics and Its Application},
keywords = {calibration,consistent scoring function,distributional regression,ensemble forecast,proper scoring,rule},
pages = {125--151},
title = {Probabilistic forecasting},
volume = {1},
year = {2014}
}
@article{Gneiting2008,
abstract = {We discuss methods for the evaluation of probabilistic predictions of vector-valued quantities, that can take the form of a discrete forecast ensemble or a density forecast. In particular, we propose a multivariate version of the univariate verification rank histogram or Talagrand diagram that can be used to check the calibration of ensemble forecasts. In the case of density forecasts, Box's density ordinate transform provides an attractive alternative. The multivariate energy score generalizes the continuous ranked probability score. It addresses both calibration and sharpness, and can be used to compare deterministic forecasts, ensemble forecasts and density forecasts, using a single loss function that is proper. An application to the University of Washington mesoscale ensemble points at strengths and deficiencies of probabilistic short-range forecasts of surface wind vectors over the North American Pacific Northwest.},
author = {Gneiting, Tilmann and Stanberry, Larissa I. and Grimit, Eric P. and Held, Leonhard and Johnson, Nicholas A.},
doi = {10.1007/s11749-008-0114-x},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gneiting et al. - 2008 - Assessing probabilistic forecasts of multivariate quantities, with an application to ensemble predictions of su.pdf:pdf},
isbn = {1174900801186},
issn = {11330686},
journal = {Test},
keywords = {Calibration,Density forecast,Ensemble postprocessing,Exchangeability,Forecast verification,Probability integral transform,Proper scoring rule,Rank histogram,Sharpness},
number = {2},
pages = {211--235},
title = {Assessing probabilistic forecasts of multivariate quantities, with an application to ensemble predictions of surface winds},
volume = {17},
year = {2008}
}
@article{Gneiting2007,
abstract = {Scoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is proper if the forecaster maximizes the expected score for an observation drawn from the distribution F if he or she issues the probabilistic forecast F, rather than G?=F. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster tomake careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand. This article reviews and develops the theory of proper scoring rules on general probability spaces, and proposes and discusses examples thereof. Proper scoring rules derive from convex functions and relate to information measures, entropy functions, and Bregman divergences. In the case of categorical variables, we prove a rigorous version of the Savage representation. Examples of scoring rules for probabilistic forecasts in the form of predictive densities include the logarithmic, spherical, pseudospherical, and quadratic scores. The continuous ranked probability score applies to probabilistic forecasts that take the form of predictive cumulative distribution functions. It generalizes the absolute error and forms a special case of a new and very general type of score, the energy score. Like many other scoring rules, the energy score admits a kernel representation in terms of negative definite functions, with links to inequalities of Hoeffding type, in both univariate and multivariate settings. Proper scoring rules for quantile and interval forecasts are also discussed.We relate proper scoring rules to Bayes factors and to cross-validation, and propose a novel form of cross-validation known as random-fold cross-validation. A case study on probabilistic weather forecasts in the North American Pacific Northwest illustrates the importance of propriety. We note optimum score approaches to point and quantile estimation, and propose the intuitively appealing interval score as a utility function in interval estimation that addresses width as well as coverage.},
author = {Gneiting, Tilmann and Raftery, Adrian E},
doi = {10.1198/016214506000001437},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gneiting, Raftery - 2007 - Strictly Proper Scoring Rules, Prediction, and Estimation.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {bayes factor,bregman divergence,brier score,coherent,continuous ranked probability score,cross-validation,distribution,entropy,kernel score,loss function,minimum contrast estimation,negative definite function,prediction interval,predictive,quantile forecast,scoring rule,skill score,strictly proper,utility function},
number = {477},
pages = {359--378},
title = {Strictly Proper Scoring Rules, Prediction, and Estimation},
volume = {102},
year = {2007}
}
@article{Jordan2017a,
abstract = {Probabilistic forecasts in the form of probability distributions over future events have become popular in several fields including meteorology, hydrology, economics, and demography. In typical applications, many alternative statistical models and data sources can be used to produce probabilistic forecasts. Hence, evaluating and selecting among competing methods is an important task. The scoringRules package for R provides functionality for comparative evaluation of probabilistic models based on proper scoring rules, covering a wide range of situations in applied work. This paper discusses implementation and usage details, presents case studies from meteorology and economics, and points to the relevant background literature.},
archivePrefix = {arXiv},
arxivId = {1709.04743},
author = {Jordan, Alexander and Kr{\"{u}}ger, Fabian and Lerch, Sebastian},
eprint = {1709.04743},
file = {:C$\backslash$:/Puwasala/PhD{\_}Monash/Research/Second year/Literature review/Evaluating probabilistic forecasts/scoringRules{\_}r.package{\_}article.pdf:pdf},
title = {Evaluating probabilistic forecasts with the {R} package {scoringRules}},
year = {2017}
}
@article{Pinson2012,
author = {Pinson, Pierre},
doi = {10.1002/qj.1873},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pinson - 2012 - Adaptive calibration of {\$}(u, v){\$}-wind ensemble forecasts.pdf:pdf},
journal = {Quarterly Journal of the Royal Meteorological Society},
keywords = {bivariate processes,ensemble prediction,near-,probabilistic calibration,recursive estimation},
pages = {1273--1284},
title = {Adaptive calibration of {\$}(u, v){\$}-wind ensemble forecasts},
volume = {138},
year = {2012}
}
@article{JeoEtAl2019,
abstract = {New methods are proposed for adjusting probabilistic forecasts to ensure coherence with the aggregation constraints inherent in temporal hierarchies. The different approaches nested within this framework include methods that exploit information at all levels of the hierarchy as well as a novel method based on cross-validation. The methods are evaluated using real data from two wind farms in Crete and electric load in Boston. For these applications, optimal decisions related to grid operations and bidding strategies are based on coherent probabilistic forecasts of energy power. Empirical evidence is also presented showing that probabilistic forecast reconciliation improves the accuracy of the probabilistic forecasts.},
author = {Jeon, Jooyoung and Panagiotelis, Anastasios and Petropoulos, Fotios},
doi = {10.1016/j.ejor.2019.05.020},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Jeon, Panagiotelis, Petropoulos - 2019 - Probabilistic forecast reconciliation with applications to wind power and electric load.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Aggregation,Cross-validation,Forecasting,Renewable energy generation,Temporal hierarchies},
number = {2},
pages = {364--379},
publisher = {Elsevier B.V.},
title = {Probabilistic forecast reconciliation with applications to wind power and electric load},
volume = {279},
year = {2019}
}
@article{AthEtAl2017,
abstract = {This paper introduces the concept of Temporal Hierarchies for time series forecasting. A temporal hierarchy can be constructed for any time series by means of non-overlapping temporal aggregation. Predictions constructed at all aggregation levels are combined with the proposed framework to result in temporally reconciled, accurate and robust forecasts. The implied com- bination mitigates modelling uncertainty, while the reconciled nature of the forecasts results in a unified prediction that supports aligned decisions at different planning horizons: from short- term operational up to long-term strategic planning. The proposed methodology is independent of forecasting models. It can embed high level managerial forecasts that incorporate complex and unstructured information with lower level statistical forecasts. Our results show that fore- casting with temporal hierarchies increases accuracy over conventional forecasting, particularly under increased modelling uncertainty. We discuss organisational implications of the temporally reconciled forecasts using a case study of Accident {\&} Emergency departments.},
author = {Athanasopoulos, George and Hyndman, Rob J and Kourentzes, Nikolaos and Petropoulos, Fotios},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Athanasopoulos et al. - 2017 - Forecasting with Temporal Hierarchies.pdf:pdf},
journal = {European Journal of Operational Research},
keywords = {forecast,hierarchical forecasting,reconciliation,temporal aggregation},
pages = {60--74},
title = {Forecasting with Temporal Hierarchies},
volume = {262},
year = {2017}
}
@article{LiTan2019,
abstract = {In recent decades, there has been significant growth in the capital market for mortality- and longevity-linked bonds. Therefore, modeling and forecasting the mortality indexes underlying these bonds have crucial implications for risk management in life insurance companies. In this paper, we propose a hierarchical reconciliation approach to constructing probabilistic forecasts for mortality bond indexes. We apply this approach to analyzing the Swiss Re Kortis bond, which is the first “longevity trend bond” introduced in the market. We express the longevity divergence index associated with the bond's principal reduction factor (PRF) in a hierarchical setting. We first adopt time-series models to obtain forecasts on each hierarchical level, and then apply a minimum trace reconciliation approach to ensure coherence of forecasts across all levels. Based on the reconciled probabilistic forecasts of the longevity divergence index, we estimate the probability distribution of the PRF of the Kortis bond, and compare our results with those stated in Standard and Poor's report on pre-sale information. We also illustrate the strong performance of the approach by comparing the reconciled forecasts with unreconciled forecasts as well as those from the bottom-up approach and the optimal combination approach. Finally, we provide first insights on the interest spread of the Kortis bond throughout its risk period 2010–2016.},
author = {Li, Han and Tang, Qihe},
doi = {10.1017/asb.2019.19},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Li, Tang - 2019 - Analyzing Mortality Bond Indexes Via Hierarchical Forecast Reconciliation.pdf:pdf},
issn = {17831350},
journal = {ASTIN Bulletin},
keywords = {Forecast reconciliation,modeling,mortality,probabilistic forecast,the Kortis bond,time-series models},
pages = {823-846},
volume = 24,
number =3,
title = {Analyzing Mortality Bond Indexes Via Hierarchical Forecast Reconciliation},
year = {2019}
}
@article{KouAth2019,
abstract = {Key to ensuring a successful tourism sector is timely policy making and detailed planning. National policy formulation and strategic planning requires long-term forecasts at an aggregate level, while regional operational decisions require short-term forecasts, relevant to local tourism operators. For aligned decisions at all levels, supporting forecasts must be ‘coherent' that is they should add up appropriately, across relevant demarcations (e.g., geographical divisions or market segments) and also across time. We propose an approach for generating coherent forecasts across both cross-sections and planning horizons for Australia. This results in significant improvements in forecast accuracy with substantial decision making benefits. Coherent forecasts help break intra- and inter-organisational information and planning silos, in a data driven fashion, blending information from different sources. This article also launches the Annals of Tourism Research Curated Collection on Tourism Demand Forecast, a special selection of research in this field.},
author = {Kourentzes, Nikolaos and Athanasopoulos, George},
doi = {10.1016/j.annals.2019.02.001},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Kourentzes, Athanasopoulos - 2019 - Cross-temporal coherent forecasts for Australian tourism(2).pdf:pdf},
issn = {01607383},
journal = {Annals of Tourism Research},
keywords = {Cross-sectional aggregation,Forecast combinations,Spatial correlations,Temporal aggregation},
pages = {393--409},
publisher = {Elsevier},
title = {Cross-temporal coherent forecasts for {Australian} tourism},
volume = {75},
year = {2019}
}

@article{KarMal2019,
abstract = {Times series often offers a natural disaggregation in a hierarchical structure. For example, product sales can come from different cities, districts, or states; or be grouped by categories and subcategories. This hierarchical structure can be useful for improving the forecast, and this strategy is known as hierarchical time series (HTS) analysis. In this work, a novel strategy for sales forecasting is proposed using Support Vector Regression (SVR) and hierarchical time series. We formalize three different hierarchical time series approaches: bottom-up SVR, top-down SVR, and middle-out SVR, and use them in a sales forecasting project for the Travel Retail Industry. Various hierarchical structures are proposed for the retail industry in order to achieve accurate product-level predictions. Experiments on these datasets demonstrate the virtues of SVR-based hierarchical time series in terms of predictive performance when compared with the traditional ARIMA and Holt-Winters approaches for this task.},
author = {Karmy, Juan Pablo and Maldonado, Sebasti{\'{a}}n},
doi = {10.1016/j.eswa.2019.06.060},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Karmy, Maldonado - 2019 - Hierarchical time series forecasting via Support Vector Regression in the European Travel Retail Industry.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Hierarchical time series,Sales forecasting,Support Vector Regression,Time series analysis},
pages = {59--73},
publisher = {Elsevier Ltd},
title = {Hierarchical time series forecasting via Support Vector Regression in the {European} Travel Retail Industry},
volume = {137},
year = {2019}
}


@inproceedings{Taieb2017,
  title={Coherent probabilistic forecasts for hierarchical time series},
  author={{Ben Taieb}, Souhaib and Taylor, James W and Hyndman, Rob J},
  booktitle={Proceedings of the 34th International Conference on Machine Learning},
  volume = {70},
  pages={3348--3357},
  year={2017},
  publisher={PMLR}
}

@article{Mahkya2017,
  title={Hierarchical time series bottom-up approach for forecast the export value in {Central Java}},
  author={Mahkya, DA and Ulama, BS and Suhartono},
  journal={Journal of Physics: Conference Series},
  volume={893},
  number={012033},
  year={2017},
  publisher={IOP Publishing}
}

@InProceedings{AlmVan2016,
author="Almeida, V{\^a}nia
and Ribeiro, Rita and Gama, Jo{\~a}o",
editor="Kim, Kuinam J.
and Joukov, Nikolai",
title="Hierarchical Time Series Forecast in Electrical Grids",
booktitle="Information Science and Applications",
year="2016",
publisher="Springer",
address="Singapore",
pages="995--1005",
abstract="Hierarchical time series is a first order of importance topic. Effectively, there are several applications where time series can be naturally disaggregated in a hierarchical structure using attributes such as geographical location, product type, etc. Power networks face interesting problems related to its transition to computer-aided grids. Data can be naturally disaggregated in a hierarchical structure, and there is the possibility to look for both single and aggregated points along the grid. Along this work, we applied different hierarchical forecasting methods to them. Three different approaches are compared, two common approaches, bottom-up approach, top-down approach and another one based on the hierarchical structure of data, the optimal regression combination. The evaluation considers short-term forecasting (24-h ahead). Additionally, we discussed the importance associated to the correlation degree among series to improve forecasting accuracy. Our results demonstrated that the hierarchical approach outperforms bottom-up approach at intermediate/high levels. At lower levels, it presents a superior performance in less homogeneous substations, i. e. for the substations linked to different type of customers. Additionally, its performance is comparable to the top-down approach at top levels. This approach revealed to be an interesting tool for hierarchical data analysis. It allows to achieve a good performance at top levels as the top-down approach and at same time it allows to capture series dynamics at bottom levels as the bottom-up.",
isbn="978-981-10-0557-2"
}


Almeida V., Ribeiro R., Gama J. (2016) Hierarchical Time Series Forecast in Electrical Grids. In: Kim K., Joukov N. (eds) Information Science and Applications (ICISA) 2016. Lecture Notes in Electrical Engineering, vol 376. Springer, Singapore


@article{Hyndman2016,
  title={Fast computation of reconciled forecasts for hierarchical and grouped time series},
  author={Hyndman, Rob J and Lee, Alan J and Wang, Earo},
  journal={Computational statistics \& data analysis},
  volume={97},
  pages={16--32},
  year={2016},
  publisher={Elsevier}
}

@article{NysEtAl2019,
abstract = {We propose four different estimators that take into account the autocorrelation structure when reconciling forecasts in a temporal hierarchy. Combining forecasts from multiple temporal aggregation levels exploits information differences and mitigates model uncertainty, while reconciliation ensures a unified prediction that supports aligned decisions at different horizons. In previous studies, weights assigned to the forecasts were given by the structure of the hierarchy or the forecast error variances without considering potential autocorrelation in the forecast errors. Our first estimator considers the autocovariance matrix within each aggregation level. Since this can be difficult to estimate, we propose a second estimator that blends autocorrelation and variance information, but only requires estimation of the first-order autocorrelation coefficient at each aggregation level. Our third and fourth estimators facilitate information sharing between aggregation levels using robust estimates of the cross-correlation matrix and its inverse. We compare the proposed estimators in a simulation study and demonstrate their usefulness through an application to short-term electricity load forecasting in four price areas in Sweden. We find that by taking account of auto- and cross-covariances when reconciling forecasts, accuracy can be significantly improved uniformly across all frequencies and areas.},
author = {Nystrup, Peter and Lindstr{\"{o}}m, Erik and Pinson, Pierre and Madsen, Henrik},
doi = {10.1016/j.ejor.2019.07.061},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Nystrup et al. - 2019 - Temporal hierarchies with autocorrelation for load forecasting.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Autocorrelation,Forecast combination,Forecasting,Reconciliation,Temporal aggregation},
number = {forthcoming},
publisher = {Elsevier B.V.},
title = {Temporal hierarchies with autocorrelation for load forecasting},
year = {2019}
}

@article{Cha2013,
abstract = {Big data is a popular term used to describe the exponential growth, availability, and use of information, both structured and unstructured. Much has been written on the big data trend and how it can serve as the basis for innovation, differentiation, and growth. Companies using real information to sense demand signals and respond quickly to changes in demand can confidently cut inventory, reduce working capital requirements, and free up cash. [PUBLICATION ABSTRACT]},
author = {Chase, Charles W.},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Chase - 2013 - Using Big Data to Enhance Demand-Driven Forecasting and Planning.pdf:pdf},
journal = {Journal of Business Forecasting},
keywords = {2310:Planning,5200:Communications {\&} information management,9190:United States,Business And Economics,Business forecasts,Demand analysis,Efficiency,Information management,United States--US},
number = {2},
pages = {27--32},
title = {Using Big Data to Enhance Demand-Driven Forecasting and Planning},
volume = {32},
year = {2013}
}

@techreport{wickramasuriya2019optimal,
	title={Optimal Non-negative Forecast Reconciliation},
	author={Wickramasuriya, Shanika and Turlach, Berwin and Hyndman, Rob},
	year={2019},
	institution={Monash Econometrics and Business Statistics Working paper series 18/19.}
}
